{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UHZ5dgtBUukH"
      },
      "outputs": [],
      "source": [
        "# load libraries\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import datetime\n",
        "# from google.colab import drive\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d21WFZCV19F",
        "outputId": "1173ee33-c071-49d0-c816-0d93d1d3ccd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EdTf6K23VyxH"
      },
      "outputs": [],
      "source": [
        "# change me, have to point to the Meteotrentino drive folder\n",
        "wk =  \"/content/drive/My Drive/10. Meteotrentino/\"\n",
        "\n",
        "# folder for the csv\n",
        "subfolder = \"CSVs/\"\n",
        "\n",
        "# select the filename, make me dynamic\n",
        "selected_dataset = \"temperature.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2OMJvpn3VN8J"
      },
      "outputs": [],
      "source": [
        "# data_path = wk+subfolder+selected_dataset\n",
        "data_path = \"../../../temperatura2_A.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1UMaZX3Ud1Q8"
      },
      "outputs": [],
      "source": [
        "df_row_data = pd.read_csv(\n",
        "  data_path,\n",
        "  sep = \";\", # not a CSV, separator is ';'\n",
        "  header = None, # no header\n",
        "  dtype = {'0' : str, '1': str, '2': str, '3' : np.float64, '4':int} # Daniele: added the validation code so we can train on validated data (no need of classes, just distinguish between good and bad data)\n",
        "  ) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lm8SzZOFhPAS"
      },
      "outputs": [],
      "source": [
        "# define a header \n",
        "df_row_data = df_row_data.set_axis(\n",
        "    ['label', 'date', 'time', 'value','validation_code'],\n",
        "    axis = 1,\n",
        "    inplace = False\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ZeP4DqRid9uB"
      },
      "outputs": [],
      "source": [
        "df_row_data['datetime'] = pd.to_datetime(df_row_data['date']+\" \"+df_row_data['time'], format = '%d/%m/%Y %H:%M')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "y8babb6JomG1",
        "outputId": "48fd8a47-813a-44ba-d901-33fd65758aa3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>value</th>\n",
              "      <th>validation_code</th>\n",
              "      <th>datetime</th>\n",
              "      <th>datetime_enconded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T0229</td>\n",
              "      <td>01/01/2014</td>\n",
              "      <td>00:00</td>\n",
              "      <td>-7.5</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-01-01 00:00:00</td>\n",
              "      <td>1388534400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T0229</td>\n",
              "      <td>01/01/2014</td>\n",
              "      <td>00:15</td>\n",
              "      <td>-9.3</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-01-01 00:15:00</td>\n",
              "      <td>1388535300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T0229</td>\n",
              "      <td>01/01/2014</td>\n",
              "      <td>00:30</td>\n",
              "      <td>-6.4</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-01-01 00:30:00</td>\n",
              "      <td>1388536200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T0229</td>\n",
              "      <td>01/01/2014</td>\n",
              "      <td>00:45</td>\n",
              "      <td>-7.7</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-01-01 00:45:00</td>\n",
              "      <td>1388537100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T0229</td>\n",
              "      <td>01/01/2014</td>\n",
              "      <td>01:00</td>\n",
              "      <td>-7.1</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-01-01 01:00:00</td>\n",
              "      <td>1388538000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11606963</th>\n",
              "      <td>T0429</td>\n",
              "      <td>31/12/2021</td>\n",
              "      <td>22:45</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-12-31 22:45:00</td>\n",
              "      <td>1640990700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11606964</th>\n",
              "      <td>T0429</td>\n",
              "      <td>31/12/2021</td>\n",
              "      <td>23:00</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-12-31 23:00:00</td>\n",
              "      <td>1640991600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11606965</th>\n",
              "      <td>T0429</td>\n",
              "      <td>31/12/2021</td>\n",
              "      <td>23:15</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-12-31 23:15:00</td>\n",
              "      <td>1640992500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11606966</th>\n",
              "      <td>T0429</td>\n",
              "      <td>31/12/2021</td>\n",
              "      <td>23:30</td>\n",
              "      <td>6.2</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-12-31 23:30:00</td>\n",
              "      <td>1640993400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11606967</th>\n",
              "      <td>T0429</td>\n",
              "      <td>31/12/2021</td>\n",
              "      <td>23:45</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-12-31 23:45:00</td>\n",
              "      <td>1640994300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11606968 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          label        date   time  value  validation_code  \\\n",
              "0         T0229  01/01/2014  00:00   -7.5                1   \n",
              "1         T0229  01/01/2014  00:15   -9.3                1   \n",
              "2         T0229  01/01/2014  00:30   -6.4                1   \n",
              "3         T0229  01/01/2014  00:45   -7.7                1   \n",
              "4         T0229  01/01/2014  01:00   -7.1                1   \n",
              "...         ...         ...    ...    ...              ...   \n",
              "11606963  T0429  31/12/2021  22:45    8.0                1   \n",
              "11606964  T0429  31/12/2021  23:00    5.1                1   \n",
              "11606965  T0429  31/12/2021  23:15    3.4                1   \n",
              "11606966  T0429  31/12/2021  23:30    6.2                1   \n",
              "11606967  T0429  31/12/2021  23:45    6.0                1   \n",
              "\n",
              "                    datetime  datetime_enconded  \n",
              "0        2014-01-01 00:00:00         1388534400  \n",
              "1        2014-01-01 00:15:00         1388535300  \n",
              "2        2014-01-01 00:30:00         1388536200  \n",
              "3        2014-01-01 00:45:00         1388537100  \n",
              "4        2014-01-01 01:00:00         1388538000  \n",
              "...                      ...                ...  \n",
              "11606963 2021-12-31 22:45:00         1640990700  \n",
              "11606964 2021-12-31 23:00:00         1640991600  \n",
              "11606965 2021-12-31 23:15:00         1640992500  \n",
              "11606966 2021-12-31 23:30:00         1640993400  \n",
              "11606967 2021-12-31 23:45:00         1640994300  \n",
              "\n",
              "[11606968 rows x 7 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# econde the date as integer\n",
        "df_row_data['datetime_enconded'] = np.int64(df_row_data['datetime'].astype(int)/10**9)\n",
        "df_row_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wVzzW1ocnOJ",
        "outputId": "761cfff2-5577-4c5e-f272-a0a3b3723003"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_28921/1736077991.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_row_data['period_index'][(df_row_data['datetime'] < offset_data) & (df_row_data['datetime'] >= current_data)] = i\n"
          ]
        }
      ],
      "source": [
        "# split the dataframe by date\n",
        "\n",
        "date_start = df_row_data['datetime'].min()\n",
        "\n",
        "date_end = df_row_data['datetime'].max()\n",
        "\n",
        "\n",
        "# period\n",
        "period_split = 24 #hours\n",
        "\n",
        "current_data = date_start\n",
        "\n",
        "df_row_data['period_index'] = [-1]*len(df_row_data['datetime'])\n",
        "\n",
        "i = 0\n",
        "while current_data < date_end:\n",
        "\n",
        "  offset_data = current_data+ pd.offsets.Hour(period_split)\n",
        "  \n",
        "  df_row_data['period_index'][(df_row_data['datetime'] < offset_data) & (df_row_data['datetime'] >= current_data)] = i\n",
        "\n",
        "  current_data = offset_data\n",
        "  i = i+1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>value</th>\n",
              "      <th>validation_code</th>\n",
              "      <th>datetime</th>\n",
              "      <th>datetime_enconded</th>\n",
              "      <th>period_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11326645</th>\n",
              "      <td>T0429</td>\n",
              "      <td>01/01/2014</td>\n",
              "      <td>00:00</td>\n",
              "      <td>-12.4</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-01-01 00:00:00</td>\n",
              "      <td>1388534400</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11326646</th>\n",
              "      <td>T0429</td>\n",
              "      <td>01/01/2014</td>\n",
              "      <td>00:15</td>\n",
              "      <td>-11.9</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-01-01 00:15:00</td>\n",
              "      <td>1388535300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11326647</th>\n",
              "      <td>T0429</td>\n",
              "      <td>01/01/2014</td>\n",
              "      <td>00:30</td>\n",
              "      <td>-11.2</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-01-01 00:30:00</td>\n",
              "      <td>1388536200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11326648</th>\n",
              "      <td>T0429</td>\n",
              "      <td>01/01/2014</td>\n",
              "      <td>00:45</td>\n",
              "      <td>-11.7</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-01-01 00:45:00</td>\n",
              "      <td>1388537100</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11326649</th>\n",
              "      <td>T0429</td>\n",
              "      <td>01/01/2014</td>\n",
              "      <td>01:00</td>\n",
              "      <td>-12.2</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-01-01 01:00:00</td>\n",
              "      <td>1388538000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11606963</th>\n",
              "      <td>T0429</td>\n",
              "      <td>31/12/2021</td>\n",
              "      <td>22:45</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-12-31 22:45:00</td>\n",
              "      <td>1640990700</td>\n",
              "      <td>2921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11606964</th>\n",
              "      <td>T0429</td>\n",
              "      <td>31/12/2021</td>\n",
              "      <td>23:00</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-12-31 23:00:00</td>\n",
              "      <td>1640991600</td>\n",
              "      <td>2921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11606965</th>\n",
              "      <td>T0429</td>\n",
              "      <td>31/12/2021</td>\n",
              "      <td>23:15</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-12-31 23:15:00</td>\n",
              "      <td>1640992500</td>\n",
              "      <td>2921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11606966</th>\n",
              "      <td>T0429</td>\n",
              "      <td>31/12/2021</td>\n",
              "      <td>23:30</td>\n",
              "      <td>6.2</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-12-31 23:30:00</td>\n",
              "      <td>1640993400</td>\n",
              "      <td>2921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11606967</th>\n",
              "      <td>T0429</td>\n",
              "      <td>31/12/2021</td>\n",
              "      <td>23:45</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-12-31 23:45:00</td>\n",
              "      <td>1640994300</td>\n",
              "      <td>2921</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>280323 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          label        date   time  value  validation_code  \\\n",
              "11326645  T0429  01/01/2014  00:00  -12.4                1   \n",
              "11326646  T0429  01/01/2014  00:15  -11.9                1   \n",
              "11326647  T0429  01/01/2014  00:30  -11.2                1   \n",
              "11326648  T0429  01/01/2014  00:45  -11.7                1   \n",
              "11326649  T0429  01/01/2014  01:00  -12.2                1   \n",
              "...         ...         ...    ...    ...              ...   \n",
              "11606963  T0429  31/12/2021  22:45    8.0                1   \n",
              "11606964  T0429  31/12/2021  23:00    5.1                1   \n",
              "11606965  T0429  31/12/2021  23:15    3.4                1   \n",
              "11606966  T0429  31/12/2021  23:30    6.2                1   \n",
              "11606967  T0429  31/12/2021  23:45    6.0                1   \n",
              "\n",
              "                    datetime  datetime_enconded  period_index  \n",
              "11326645 2014-01-01 00:00:00         1388534400             0  \n",
              "11326646 2014-01-01 00:15:00         1388535300             0  \n",
              "11326647 2014-01-01 00:30:00         1388536200             0  \n",
              "11326648 2014-01-01 00:45:00         1388537100             0  \n",
              "11326649 2014-01-01 01:00:00         1388538000             0  \n",
              "...                      ...                ...           ...  \n",
              "11606963 2021-12-31 22:45:00         1640990700          2921  \n",
              "11606964 2021-12-31 23:00:00         1640991600          2921  \n",
              "11606965 2021-12-31 23:15:00         1640992500          2921  \n",
              "11606966 2021-12-31 23:30:00         1640993400          2921  \n",
              "11606967 2021-12-31 23:45:00         1640994300          2921  \n",
              "\n",
              "[280323 rows x 8 columns]"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_row_data.loc[df_row_data['label']=='T0429']\n",
        "print( np.unique(df_row_data['label']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCWa6VKCfsm2"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "pVSUTFnJjwgg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T0357\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>in_datetime</th>\n",
              "      <th>in_datetime_int</th>\n",
              "      <th>val_label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>...</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-02-15</td>\n",
              "      <td>1392422400</td>\n",
              "      <td>bad</td>\n",
              "      <td>-8.7</td>\n",
              "      <td>-9.1</td>\n",
              "      <td>-9.4</td>\n",
              "      <td>-9.5</td>\n",
              "      <td>-9.5</td>\n",
              "      <td>-9.4</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-1.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-02-16</td>\n",
              "      <td>1392508800</td>\n",
              "      <td>bad</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>-1.2</td>\n",
              "      <td>-1.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-02-17</td>\n",
              "      <td>1392595200</td>\n",
              "      <td>bad</td>\n",
              "      <td>-1.3</td>\n",
              "      <td>-1.3</td>\n",
              "      <td>-1.3</td>\n",
              "      <td>-1.3</td>\n",
              "      <td>-1.3</td>\n",
              "      <td>-1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>-1.2</td>\n",
              "      <td>-1.2</td>\n",
              "      <td>-1.2</td>\n",
              "      <td>-1.2</td>\n",
              "      <td>-1.2</td>\n",
              "      <td>-1.2</td>\n",
              "      <td>-1.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-02-18</td>\n",
              "      <td>1392681600</td>\n",
              "      <td>bad</td>\n",
              "      <td>-1.2</td>\n",
              "      <td>-1.3</td>\n",
              "      <td>-1.3</td>\n",
              "      <td>-1.3</td>\n",
              "      <td>-1.3</td>\n",
              "      <td>-1.3</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-02-19</td>\n",
              "      <td>1392768000</td>\n",
              "      <td>bad</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-02-20</td>\n",
              "      <td>1392854400</td>\n",
              "      <td>bad</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>-2.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-02-21</td>\n",
              "      <td>1392940800</td>\n",
              "      <td>bad</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>-2.6</td>\n",
              "      <td>-2.7</td>\n",
              "      <td>-2.8</td>\n",
              "      <td>-2.9</td>\n",
              "      <td>-2.9</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>-2.6</td>\n",
              "      <td>-2.6</td>\n",
              "      <td>-2.6</td>\n",
              "      <td>-2.6</td>\n",
              "      <td>-2.6</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>-2.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-02-22</td>\n",
              "      <td>1393027200</td>\n",
              "      <td>bad</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.7</td>\n",
              "      <td>-2.7</td>\n",
              "      <td>-2.8</td>\n",
              "      <td>-2.9</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-3.1</td>\n",
              "      <td>-3.1</td>\n",
              "      <td>-3.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-02-23</td>\n",
              "      <td>1393113600</td>\n",
              "      <td>bad</td>\n",
              "      <td>-3.2</td>\n",
              "      <td>-3.2</td>\n",
              "      <td>-3.3</td>\n",
              "      <td>-3.3</td>\n",
              "      <td>-3.4</td>\n",
              "      <td>-3.4</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-4.1</td>\n",
              "      <td>-4.2</td>\n",
              "      <td>-4.2</td>\n",
              "      <td>-4.2</td>\n",
              "      <td>-4.3</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-4.5</td>\n",
              "      <td>-4.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-02-24</td>\n",
              "      <td>1393200000</td>\n",
              "      <td>bad</td>\n",
              "      <td>-4.7</td>\n",
              "      <td>-4.7</td>\n",
              "      <td>-4.7</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-4.3</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.1</td>\n",
              "      <td>-3.2</td>\n",
              "      <td>-3.4</td>\n",
              "      <td>-3.6</td>\n",
              "      <td>-3.7</td>\n",
              "      <td>-3.5</td>\n",
              "      <td>-3.2</td>\n",
              "      <td>-2.9</td>\n",
              "      <td>-2.7</td>\n",
              "      <td>-2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-02-25</td>\n",
              "      <td>1393286400</td>\n",
              "      <td>bad</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>-2.4</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>-2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-02-26</td>\n",
              "      <td>1393372800</td>\n",
              "      <td>bad</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>-2.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-02-27</td>\n",
              "      <td>1393459200</td>\n",
              "      <td>bad</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>-1.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-02-28</td>\n",
              "      <td>1393545600</td>\n",
              "      <td>bad</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-03-01</td>\n",
              "      <td>1393632000</td>\n",
              "      <td>bad</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-4.1</td>\n",
              "      <td>-4.2</td>\n",
              "      <td>-4.2</td>\n",
              "      <td>-4.3</td>\n",
              "      <td>-4.3</td>\n",
              "      <td>-4.3</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-03-02</td>\n",
              "      <td>1393718400</td>\n",
              "      <td>bad</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>-1.8</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-03-03</td>\n",
              "      <td>1393804800</td>\n",
              "      <td>bad</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.6</td>\n",
              "      <td>-2.6</td>\n",
              "      <td>-2.7</td>\n",
              "      <td>-2.8</td>\n",
              "      <td>-2.8</td>\n",
              "      <td>-2.8</td>\n",
              "      <td>-2.8</td>\n",
              "      <td>-2.8</td>\n",
              "      <td>-2.9</td>\n",
              "      <td>-2.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-03-04</td>\n",
              "      <td>1393891200</td>\n",
              "      <td>bad</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-2.9</td>\n",
              "      <td>-2.9</td>\n",
              "      <td>-2.9</td>\n",
              "      <td>-2.9</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.2</td>\n",
              "      <td>-4.2</td>\n",
              "      <td>-4.2</td>\n",
              "      <td>-4.3</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-4.4</td>\n",
              "      <td>-4.5</td>\n",
              "      <td>-4.7</td>\n",
              "      <td>-4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-03-05</td>\n",
              "      <td>1393977600</td>\n",
              "      <td>bad</td>\n",
              "      <td>-4.9</td>\n",
              "      <td>-4.9</td>\n",
              "      <td>-4.9</td>\n",
              "      <td>-4.9</td>\n",
              "      <td>-4.9</td>\n",
              "      <td>-4.9</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.2</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>-5.4</td>\n",
              "      <td>-5.4</td>\n",
              "      <td>-5.3</td>\n",
              "      <td>-5.4</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>-5.5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-03-06</td>\n",
              "      <td>1394064000</td>\n",
              "      <td>bad</td>\n",
              "      <td>-5.7</td>\n",
              "      <td>-5.8</td>\n",
              "      <td>-5.9</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>-6.3</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.9</td>\n",
              "      <td>-4.9</td>\n",
              "      <td>-4.7</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>-4.5</td>\n",
              "      <td>-4.3</td>\n",
              "      <td>-4.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-03-07</td>\n",
              "      <td>1394150400</td>\n",
              "      <td>bad</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-3.9</td>\n",
              "      <td>-3.8</td>\n",
              "      <td>-3.8</td>\n",
              "      <td>-3.8</td>\n",
              "      <td>-3.8</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>-2.1</td>\n",
              "      <td>-2.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>T0357</td>\n",
              "      <td>2014-03-08</td>\n",
              "      <td>1394236800</td>\n",
              "      <td>bad</td>\n",
              "      <td>-2.3</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>-2.6</td>\n",
              "      <td>-2.9</td>\n",
              "      <td>-3.1</td>\n",
              "      <td>-3.1</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.9</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-5.1</td>\n",
              "      <td>-5.2</td>\n",
              "      <td>-5.3</td>\n",
              "      <td>-5.3</td>\n",
              "      <td>-5.4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    label in_datetime  in_datetime_int val_label    0    1    2    3    4  \\\n",
              "45  T0357  2014-02-15       1392422400       bad -8.7 -9.1 -9.4 -9.5 -9.5   \n",
              "46  T0357  2014-02-16       1392508800       bad -1.6 -1.6 -1.6 -1.6 -1.6   \n",
              "47  T0357  2014-02-17       1392595200       bad -1.3 -1.3 -1.3 -1.3 -1.3   \n",
              "48  T0357  2014-02-18       1392681600       bad -1.2 -1.3 -1.3 -1.3 -1.3   \n",
              "49  T0357  2014-02-19       1392768000       bad -0.6 -0.6 -0.6 -0.6 -0.6   \n",
              "50  T0357  2014-02-20       1392854400       bad -0.7 -0.7 -0.7 -0.7 -0.7   \n",
              "51  T0357  2014-02-21       1392940800       bad -2.5 -2.6 -2.7 -2.8 -2.9   \n",
              "52  T0357  2014-02-22       1393027200       bad -2.3 -2.2 -2.2 -2.2 -2.2   \n",
              "53  T0357  2014-02-23       1393113600       bad -3.2 -3.2 -3.3 -3.3 -3.4   \n",
              "54  T0357  2014-02-24       1393200000       bad -4.7 -4.7 -4.7 -4.6 -4.4   \n",
              "55  T0357  2014-02-25       1393286400       bad -2.5 -2.5 -2.5 -2.5 -2.5   \n",
              "56  T0357  2014-02-26       1393372800       bad -2.2 -2.2 -2.2 -2.2 -2.2   \n",
              "57  T0357  2014-02-27       1393459200       bad -2.3 -2.3 -2.3 -2.3 -2.3   \n",
              "58  T0357  2014-02-28       1393545600       bad -1.9 -1.9 -1.9 -1.9 -1.9   \n",
              "59  T0357  2014-03-01       1393632000       bad -1.9 -2.0 -2.0 -2.1 -2.1   \n",
              "60  T0357  2014-03-02       1393718400       bad -4.4 -4.4 -4.4 -4.4 -4.4   \n",
              "61  T0357  2014-03-03       1393804800       bad -2.0 -2.0 -2.0 -2.0 -2.0   \n",
              "62  T0357  2014-03-04       1393891200       bad -3.0 -2.9 -2.9 -2.9 -2.9   \n",
              "63  T0357  2014-03-05       1393977600       bad -4.9 -4.9 -4.9 -4.9 -4.9   \n",
              "64  T0357  2014-03-06       1394064000       bad -5.7 -5.8 -5.9 -6.0 -6.0   \n",
              "65  T0357  2014-03-07       1394150400       bad -4.0 -3.9 -3.8 -3.8 -3.8   \n",
              "66  T0357  2014-03-08       1394236800       bad -2.3 -2.5 -2.6 -2.9 -3.1   \n",
              "\n",
              "      5  ...   86   87   88   89   90   91   92   93   94   95  \n",
              "45 -9.4  ... -1.7 -1.7 -1.7 -1.7 -1.7 -1.7 -1.7 -1.7 -1.7 -1.7  \n",
              "46 -1.6  ... -1.0 -1.0 -1.1 -1.1 -1.1 -1.1 -1.1 -1.1 -1.2 -1.2  \n",
              "47 -1.3  ... -1.1 -1.1 -1.1 -1.2 -1.2 -1.2 -1.2 -1.2 -1.2 -1.2  \n",
              "48 -1.3  ... -0.9 -0.8 -0.8 -0.8 -0.7 -0.7 -0.7 -0.7 -0.7 -0.6  \n",
              "49 -0.6  ... -0.7 -0.7 -0.7 -0.7 -0.7 -0.7 -0.7 -0.7 -0.7 -0.7  \n",
              "50 -0.7  ... -1.6 -1.7 -1.7 -1.8 -1.9 -1.9 -2.1 -2.2 -2.3 -2.4  \n",
              "51 -2.9  ... -2.5 -2.5 -2.5 -2.6 -2.6 -2.6 -2.6 -2.6 -2.5 -2.4  \n",
              "52 -2.2  ... -2.7 -2.7 -2.8 -2.9 -3.0 -3.0 -3.0 -3.1 -3.1 -3.1  \n",
              "53 -3.4  ... -4.0 -4.1 -4.2 -4.2 -4.2 -4.3 -4.4 -4.4 -4.5 -4.6  \n",
              "54 -4.3  ... -3.1 -3.2 -3.4 -3.6 -3.7 -3.5 -3.2 -2.9 -2.7 -2.5  \n",
              "55 -2.4  ... -2.0 -2.0 -2.0 -2.0 -2.1 -2.1 -2.1 -2.1 -2.2 -2.2  \n",
              "56 -2.2  ... -2.1 -2.1 -2.1 -2.1 -2.1 -2.2 -2.2 -2.2 -2.2 -2.3  \n",
              "57 -2.3  ... -1.7 -1.7 -1.7 -1.7 -1.7 -1.7 -1.8 -1.8 -1.8 -1.8  \n",
              "58 -1.9  ... -1.8 -1.8 -1.8 -1.8 -1.8 -1.9 -1.9 -1.9 -1.9 -1.9  \n",
              "59 -2.1  ... -4.0 -4.1 -4.2 -4.2 -4.3 -4.3 -4.3 -4.4 -4.4 -4.4  \n",
              "60 -4.4  ... -1.8 -1.8 -1.9 -1.9 -1.9 -1.9 -1.9 -1.9 -1.9 -1.9  \n",
              "61 -2.0  ... -2.6 -2.6 -2.7 -2.8 -2.8 -2.8 -2.8 -2.8 -2.9 -2.9  \n",
              "62 -3.0  ... -4.2 -4.2 -4.2 -4.3 -4.4 -4.4 -4.4 -4.5 -4.7 -4.8  \n",
              "63 -4.9  ... -5.2 -5.5 -5.5 -5.4 -5.4 -5.3 -5.4 -5.5 -5.5  NaN  \n",
              "64 -6.3  ... -4.9 -4.9 -4.7 -4.6 -4.6 -4.6 -4.6 -4.5 -4.3 -4.2  \n",
              "65 -3.8  ... -1.6 -1.9 -2.1 -2.2 -2.1 -2.1 -2.2  NaN  NaN  NaN  \n",
              "66 -3.1  ... -4.9 -5.0 -5.0 -5.1 -5.2 -5.3 -5.3 -5.4  NaN  NaN  \n",
              "\n",
              "[22 rows x 100 columns]"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_arr = []\n",
        "\n",
        "for station in ['T0357']:\n",
        "  df_station = df_row_data.loc[df_row_data['label']==station]\n",
        "  for pk in np.unique(df_station['period_index']):\n",
        "    df_subset = df_station.loc[(df_row_data['period_index'] == pk)]\n",
        "    \n",
        "    if df_subset.empty:\n",
        "      continue\n",
        "\n",
        "    if((df_subset['validation_code'].values != 1).any()):\n",
        "      val_label = 'bad'\n",
        "    else:\n",
        "      val_label = 'good'\n",
        "\n",
        "    header={\n",
        "      'label':df_subset['label'].values[0],\n",
        "      'in_datetime':df_subset['datetime'].values[0],\n",
        "      'in_datetime_int':df_subset['datetime_enconded'].values[0],\n",
        "      'val_label':val_label\n",
        "    }\n",
        "\n",
        "    features = df_subset['value'].reset_index(drop=True).to_dict()\n",
        "    data_arr.append({**header,**features})\n",
        "df_row_data_converted = pd.DataFrame(data_arr)\n",
        "df_row_data_converted.loc[df_row_data_converted['val_label']=='bad']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 341,
      "metadata": {
        "id": "y1JJEnKdd-67"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# create pythorc class for the data\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, df, transform = None, target_transform = None):\n",
        "    self.features = torch.FloatTensor(df.drop(['label','in_datetime','in_datetime_int','val_label'],axis=1).values)\n",
        "    ### standardize the data\n",
        "    mean, std= torch.mean(self.features,0), torch.std(self.features,0)\n",
        "    self.features = (self.features-mean)/std\n",
        "\n",
        "    self.label = df['label'].values\n",
        "    self.in_datetime = df['in_datetime'].values\n",
        "    self.in_datetime_int = df['in_datetime_int'].values\n",
        "    self.val_label = df['val_label'].values\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    features = self.features[idx]\n",
        "    label = self.label[idx]\n",
        "    date = self.in_datetime[idx]\n",
        "    val_label = self.val_label[idx]\n",
        "    return {\"label\": label, \"features\": features, \"val_label\":val_label, \"date\":date}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 377,
      "metadata": {
        "id": "0O9aZkGqryYP"
      },
      "outputs": [],
      "source": [
        "# define the dataset and split in train and test\n",
        "splits = ['train','test']\n",
        "shuffle = {'train':True,'test':False}\n",
        "dataset = {}\n",
        "\n",
        "df_row_data_converted = df_row_data_converted.dropna().reset_index(drop=True)\n",
        "\n",
        "good_samples = df_row_data_converted.loc[df_row_data_converted['val_label']=='good']\n",
        "bad_samples = df_row_data_converted.loc[df_row_data_converted['val_label']=='bad']\n",
        "\n",
        "# Test dataframe is made of all bad samples plus an equal number of good ones\n",
        "test_part_good = good_samples.sample(n = len(bad_samples))\n",
        "test = pd.concat([test_part_good, bad_samples], axis = 0)\n",
        "\n",
        "# Train dataframe is made of all good samples \n",
        "train = good_samples.drop(test_part_good.index)\n",
        "\n",
        "dataset['train'] = CustomDataset(train)\n",
        "dataset['test'] = CustomDataset( test )\n",
        "b_size = {'train':12,'test':len(dataset['test'])}\n",
        "\n",
        "dataloader = {x: torch.utils.data.DataLoader(dataset=dataset[x],\n",
        "                                            batch_size=b_size[x],\n",
        "                                            shuffle=shuffle[x],\n",
        "                                            collate_fn=lambda x: x)\n",
        "                                            #num_workers=int(opt.workers),\n",
        "                                            #drop_last=drop_last_batch[x],\n",
        "                                            #worker_init_fn=(None if opt.manualseed == -1\n",
        "                                            #else lambda x: np.random.seed(opt.manualseed)))\n",
        "            for x in splits}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 422,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 351.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 1/100\n",
            ">> Training loss: 0.24828879535198212\n",
            ">> Validation loss: 1.0299310684204102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 454.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 2/100\n",
            ">> Training loss: 1.0914562940597534\n",
            ">> Validation loss: 0.8490127921104431\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 415.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 3/100\n",
            ">> Training loss: 0.13324131071567535\n",
            ">> Validation loss: 0.6449625492095947\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 454.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 4/100\n",
            ">> Training loss: 0.23125021159648895\n",
            ">> Validation loss: 0.4912521541118622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 484.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 5/100\n",
            ">> Training loss: 0.03495529666543007\n",
            ">> Validation loss: 0.40298616886138916\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 473.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 6/100\n",
            ">> Training loss: 0.09271296113729477\n",
            ">> Validation loss: 0.3518592119216919\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 488.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 7/100\n",
            ">> Training loss: 0.03252787888050079\n",
            ">> Validation loss: 0.3123932480812073\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 466.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 8/100\n",
            ">> Training loss: 1.221396803855896\n",
            ">> Validation loss: 0.2737598717212677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 485.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 9/100\n",
            ">> Training loss: 0.8805422782897949\n",
            ">> Validation loss: 0.23280324041843414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 473.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 10/100\n",
            ">> Training loss: 0.37007367610931396\n",
            ">> Validation loss: 0.19097650051116943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 501.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 11/100\n",
            ">> Training loss: 0.012233011424541473\n",
            ">> Validation loss: 0.1503099650144577\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 441.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 12/100\n",
            ">> Training loss: 0.01253869105130434\n",
            ">> Validation loss: 0.11323188245296478\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 483.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 13/100\n",
            ">> Training loss: 0.01683666557073593\n",
            ">> Validation loss: 0.08243478834629059\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 474.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 14/100\n",
            ">> Training loss: 0.02257367968559265\n",
            ">> Validation loss: 0.0596979558467865\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 463.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 15/100\n",
            ">> Training loss: 0.09294396638870239\n",
            ">> Validation loss: 0.04516129195690155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 470.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 16/100\n",
            ">> Training loss: 0.01788480207324028\n",
            ">> Validation loss: 0.03681733459234238\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 474.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 17/100\n",
            ">> Training loss: 0.1332295686006546\n",
            ">> Validation loss: 0.03284193202853203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 457.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 18/100\n",
            ">> Training loss: 0.11640852689743042\n",
            ">> Validation loss: 0.03065348230302334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 459.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 19/100\n",
            ">> Training loss: 0.05461544916033745\n",
            ">> Validation loss: 0.029715433716773987\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 490.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 20/100\n",
            ">> Training loss: 0.0970262959599495\n",
            ">> Validation loss: 0.028905801475048065\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 458.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 21/100\n",
            ">> Training loss: 0.01785345934331417\n",
            ">> Validation loss: 0.028487280011177063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 466.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 22/100\n",
            ">> Training loss: 0.022480756044387817\n",
            ">> Validation loss: 0.028023408725857735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 438.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 23/100\n",
            ">> Training loss: 0.1267763078212738\n",
            ">> Validation loss: 0.027790607884526253\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 461.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 24/100\n",
            ">> Training loss: 0.04448598250746727\n",
            ">> Validation loss: 0.02718614786863327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 474.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 25/100\n",
            ">> Training loss: 0.06577485054731369\n",
            ">> Validation loss: 0.02694467082619667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 448.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 26/100\n",
            ">> Training loss: 0.0153512479737401\n",
            ">> Validation loss: 0.02624901756644249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 480.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 27/100\n",
            ">> Training loss: 0.06041628122329712\n",
            ">> Validation loss: 0.02588261291384697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 437.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 28/100\n",
            ">> Training loss: 0.01384724210947752\n",
            ">> Validation loss: 0.02540474198758602\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 455.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 29/100\n",
            ">> Training loss: 0.03233983367681503\n",
            ">> Validation loss: 0.025031136348843575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 457.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 30/100\n",
            ">> Training loss: 0.014431544579565525\n",
            ">> Validation loss: 0.02443147823214531\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 467.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 31/100\n",
            ">> Training loss: 0.026983624324202538\n",
            ">> Validation loss: 0.023972947150468826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 484.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 32/100\n",
            ">> Training loss: 0.024828163906931877\n",
            ">> Validation loss: 0.02384442463517189\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 462.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 33/100\n",
            ">> Training loss: 0.07900027185678482\n",
            ">> Validation loss: 0.023435592651367188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 476.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 34/100\n",
            ">> Training loss: 0.017761530354619026\n",
            ">> Validation loss: 0.022587236016988754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 484.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 35/100\n",
            ">> Training loss: 0.053551819175481796\n",
            ">> Validation loss: 0.021947277709841728\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 471.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 36/100\n",
            ">> Training loss: 0.039311494678258896\n",
            ">> Validation loss: 0.021456176415085793\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 497.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 37/100\n",
            ">> Training loss: 0.020609650760889053\n",
            ">> Validation loss: 0.021131014451384544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 461.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 38/100\n",
            ">> Training loss: 0.05196455121040344\n",
            ">> Validation loss: 0.020900771021842957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 485.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 39/100\n",
            ">> Training loss: 0.09272265434265137\n",
            ">> Validation loss: 0.02029854618012905\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 460.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 40/100\n",
            ">> Training loss: 0.030715899541974068\n",
            ">> Validation loss: 0.019733231514692307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 477.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 41/100\n",
            ">> Training loss: 0.010966540314257145\n",
            ">> Validation loss: 0.01948419213294983\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 480.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 42/100\n",
            ">> Training loss: 0.0630432665348053\n",
            ">> Validation loss: 0.019099712371826172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 500.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 43/100\n",
            ">> Training loss: 0.03236917406320572\n",
            ">> Validation loss: 0.018650442361831665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 477.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 44/100\n",
            ">> Training loss: 0.05036386847496033\n",
            ">> Validation loss: 0.01857493631541729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 455.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 45/100\n",
            ">> Training loss: 0.037278566509485245\n",
            ">> Validation loss: 0.018325408920645714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 479.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 46/100\n",
            ">> Training loss: 0.02104119025170803\n",
            ">> Validation loss: 0.01775522530078888\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 418.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 47/100\n",
            ">> Training loss: 0.017376704141497612\n",
            ">> Validation loss: 0.017688903957605362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 463.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 48/100\n",
            ">> Training loss: 0.028042277321219444\n",
            ">> Validation loss: 0.017446648329496384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 424.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 49/100\n",
            ">> Training loss: 0.05193124711513519\n",
            ">> Validation loss: 0.017228860408067703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 485.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 50/100\n",
            ">> Training loss: 0.05511033162474632\n",
            ">> Validation loss: 0.01681818626821041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 473.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 51/100\n",
            ">> Training loss: 0.0153553681448102\n",
            ">> Validation loss: 0.016361577436327934\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 475.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 52/100\n",
            ">> Training loss: 0.04545186087489128\n",
            ">> Validation loss: 0.016450079157948494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 473.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 53/100\n",
            ">> Training loss: 0.006516279187053442\n",
            ">> Validation loss: 0.015890056267380714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 471.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 54/100\n",
            ">> Training loss: 0.012313802726566792\n",
            ">> Validation loss: 0.01570717617869377\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 478.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 55/100\n",
            ">> Training loss: 0.060966312885284424\n",
            ">> Validation loss: 0.015377435833215714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 447.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 56/100\n",
            ">> Training loss: 0.019317183643579483\n",
            ">> Validation loss: 0.015586620196700096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 468.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 57/100\n",
            ">> Training loss: 0.04999774321913719\n",
            ">> Validation loss: 0.01524471864104271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 479.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 58/100\n",
            ">> Training loss: 0.07136982679367065\n",
            ">> Validation loss: 0.014749819412827492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 486.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 59/100\n",
            ">> Training loss: 0.024716360494494438\n",
            ">> Validation loss: 0.014618663117289543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 451.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 60/100\n",
            ">> Training loss: 0.06824035197496414\n",
            ">> Validation loss: 0.0140739930793643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 480.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 61/100\n",
            ">> Training loss: 0.02054685540497303\n",
            ">> Validation loss: 0.0140854986384511\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 486.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 62/100\n",
            ">> Training loss: 0.028709910809993744\n",
            ">> Validation loss: 0.01414787769317627\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 470.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 63/100\n",
            ">> Training loss: 0.05096213519573212\n",
            ">> Validation loss: 0.013725535944104195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 502.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 64/100\n",
            ">> Training loss: 0.0981752872467041\n",
            ">> Validation loss: 0.0135370884090662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 449.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 65/100\n",
            ">> Training loss: 0.07523511350154877\n",
            ">> Validation loss: 0.01348778698593378\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 492.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 66/100\n",
            ">> Training loss: 0.00818711705505848\n",
            ">> Validation loss: 0.013045988976955414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 427.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 67/100\n",
            ">> Training loss: 0.01815004087984562\n",
            ">> Validation loss: 0.012859836220741272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 450.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 68/100\n",
            ">> Training loss: 0.03813746199011803\n",
            ">> Validation loss: 0.01283668540418148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 498.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 69/100\n",
            ">> Training loss: 0.007307225838303566\n",
            ">> Validation loss: 0.012580185197293758\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 454.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 70/100\n",
            ">> Training loss: 0.01978284679353237\n",
            ">> Validation loss: 0.012515399605035782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 502.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 71/100\n",
            ">> Training loss: 0.03927352651953697\n",
            ">> Validation loss: 0.012200228869915009\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 449.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 72/100\n",
            ">> Training loss: 0.05174094811081886\n",
            ">> Validation loss: 0.012083426117897034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 492.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 73/100\n",
            ">> Training loss: 0.029674209654331207\n",
            ">> Validation loss: 0.011919950135052204\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 496.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 74/100\n",
            ">> Training loss: 0.010117586702108383\n",
            ">> Validation loss: 0.011711189523339272\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 460.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 75/100\n",
            ">> Training loss: 0.01415294874459505\n",
            ">> Validation loss: 0.011581601575016975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 474.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 76/100\n",
            ">> Training loss: 0.01117552537471056\n",
            ">> Validation loss: 0.011448778212070465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 444.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 77/100\n",
            ">> Training loss: 0.03495776653289795\n",
            ">> Validation loss: 0.011210200376808643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 489.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 78/100\n",
            ">> Training loss: 0.012411460280418396\n",
            ">> Validation loss: 0.010952983982861042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 451.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 79/100\n",
            ">> Training loss: 0.09934625029563904\n",
            ">> Validation loss: 0.010742701590061188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 447.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 80/100\n",
            ">> Training loss: 0.027872517704963684\n",
            ">> Validation loss: 0.010714122094213963\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 436.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 81/100\n",
            ">> Training loss: 0.13539211452007294\n",
            ">> Validation loss: 0.010411052964627743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 487.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 82/100\n",
            ">> Training loss: 0.006797491107136011\n",
            ">> Validation loss: 0.010235413908958435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 497.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 83/100\n",
            ">> Training loss: 0.016827821731567383\n",
            ">> Validation loss: 0.010258708149194717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 464.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 84/100\n",
            ">> Training loss: 0.0051828534342348576\n",
            ">> Validation loss: 0.010030730627477169\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 465.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 85/100\n",
            ">> Training loss: 0.03630589693784714\n",
            ">> Validation loss: 0.009883840568363667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 490.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 86/100\n",
            ">> Training loss: 0.005673456937074661\n",
            ">> Validation loss: 0.009467219933867455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 458.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 87/100\n",
            ">> Training loss: 0.010422813706099987\n",
            ">> Validation loss: 0.009280828759074211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 434.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 88/100\n",
            ">> Training loss: 0.012823258526623249\n",
            ">> Validation loss: 0.009172082878649235\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 498.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 89/100\n",
            ">> Training loss: 0.007424740586429834\n",
            ">> Validation loss: 0.009008432738482952\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 479.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 90/100\n",
            ">> Training loss: 0.009938309900462627\n",
            ">> Validation loss: 0.008840187452733517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 498.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 91/100\n",
            ">> Training loss: 0.028314704075455666\n",
            ">> Validation loss: 0.008638396859169006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 442.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 92/100\n",
            ">> Training loss: 0.004889167845249176\n",
            ">> Validation loss: 0.008355841040611267\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 479.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 93/100\n",
            ">> Training loss: 0.03326931968331337\n",
            ">> Validation loss: 0.008328030817210674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 441.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 94/100\n",
            ">> Training loss: 0.01200619712471962\n",
            ">> Validation loss: 0.008090746589004993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 467.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 95/100\n",
            ">> Training loss: 0.05511453375220299\n",
            ">> Validation loss: 0.00812144111841917\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 484.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 96/100\n",
            ">> Training loss: 0.005117896944284439\n",
            ">> Validation loss: 0.007903802208602428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 467.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 97/100\n",
            ">> Training loss: 0.012657876126468182\n",
            ">> Validation loss: 0.007797053083777428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 497.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 98/100\n",
            ">> Training loss: 0.020055027678608894\n",
            ">> Validation loss: 0.007506189867854118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 412.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 99/100\n",
            ">> Training loss: 0.043969396501779556\n",
            ">> Validation loss: 0.0072409287095069885\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 238/238 [00:00<00:00, 480.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Training model AE_1D. Epoch 100/100\n",
            ">> Training loss: 0.019013315439224243\n",
            ">> Validation loss: 0.007390656974166632\n",
            ">> Training model AE_1D.[Done]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f0752359fa0>]"
            ]
          },
          "execution_count": 422,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from importlib import reload  # Python 3.4+\n",
        "model_simpleAE = reload(model_simpleAE)\n",
        "from model_simpleAE import AE_1D\n",
        "from options import Options\n",
        "\n",
        "class configuration(object):\n",
        "      \n",
        "    def __init__(self, my_dict):\n",
        "          \n",
        "        for key in my_dict:\n",
        "            setattr(self, key, my_dict[key])\n",
        "\n",
        "# LOAD MODEL\n",
        "opt_dict = {\n",
        "    'batchsize': 12,\n",
        "    'isize': 96,\n",
        "    'lsize':15, \n",
        "    'device': 'cpu',\n",
        "    'name': 'try1',\n",
        "    'outf': './output', \n",
        "    'phase': 'train',\n",
        "    'iter': 0, \n",
        "    'niter': 100,\n",
        "    'lr': 1e-5, \n",
        "}\n",
        "\n",
        "opt = configuration(opt_dict)\n",
        "opt.isTrain = True\n",
        "\n",
        "model = AE_1D(opt, dataloader)\n",
        "##\n",
        "# TRAIN MODEL\n",
        "metrics = model.train()\n",
        "\n",
        "metrics = pd.DataFrame(metrics)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(metrics['loss_tr'])\n",
        "plt.plot(metrics['loss_val'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 428,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bad\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sample = next(iter(dataloader['train']))\n",
        "sample_tensor = sample[-2]['features']\n",
        "sample_validation = sample[-2]['val_label']\n",
        "model.ae.eval()\n",
        "with torch.no_grad():\n",
        "    reconstructed = model.ae(torch.unsqueeze(sample_tensor,0))\n",
        "\n",
        "print(sample_validation)\n",
        "plt.plot(sample_tensor)\n",
        "plt.plot(reconstructed[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3g942h7xmOun"
      },
      "outputs": [],
      "source": [
        "# save the classes in the typical pytorch class format\n",
        "\n",
        "for i, class_d in enumerate(data_class_arr):\n",
        "  \n",
        "  save(class_d, wk + subfolder + \"split_by_period/\"+str(period_split)+\"h/\"+str(selected_dataset[:-4])+\"/split_\"+str(i)+\".pt\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "db3b0be3bb1f6db1a0432c56ec1c0f7459936b81fd9ed1b468b8c4ba9c3d8298"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
